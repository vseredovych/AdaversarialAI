% -*- mode: LaTeX; coding: utf8; -*-

\documentclass[a4paper,14pt]{extreport}

% правильне кодування
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[ukrainian]{babel}

% починати абзаци невеликим відступом першого рядка
\usepackage{indentfirst}
\usepackage[pdftex,unicode,bookmarks]{hyperref}

\usepackage{color}
\definecolor{bluegray}{RGB}{230,230,255}
\usepackage{listings}

\lstset{
	extendedchars=\true, % дозволити кирилицю в лінстингу
	inputencoding=utf8,
	breaklines=true,
	basicstyle=\ttfamily,
	numbers=left,
	frame=single,
	backgroundcolor=\color{bluegray}
}

% якщо прийдеться вставляти код (простіше ніж listings, але немає breaklines)
\usepackage{verbatim}

% інтервал - півтора. 
\usepackage{setspace}
\onehalfspacing

% поля
\usepackage{geometry}
\geometry{a4paper}
\geometry{left=35mm,right=15mm,top=20mm,bottom=20mm}
\geometry{headheight=2ex,headsep=10mm,footskip=10mm}

%
\usepackage{mathtools}
\usepackage{amsmath}

%для картинок
\usepackage{graphicx}
\usepackage{caption}

% lstlisting settings
\usepackage{xcolor}

% для часткових похыдних
\usepackage{physics}


% для алгоритмів
\usepackage[ruled,vlined]{algorithm2e}


\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}
\lstset{style=mystyle}


% custom commands
\newcommand{\tran}{^{T}}
\newcommand{\ith}{^{(i)}}
%\newcommand{\someth}[1]{^{(#1)}}


\begin{document}
	% ======================================================================================== %
	\begin{titlepage}%
    	\begin{center}
	    	{ЛЬВІВСЬКИЙ НАЦІОНАЛЬНИЙ УНІВЕРСИТЕТ \\ІМЕНІ ІВАНА ФРАНКА}\par
	       	{ФAКУЛЬТЕТ ПРИКЛАДНОЇ МАТЕМАТИКИ ТА ІНФОРМАТИКИ\\ КАФЕДРА ОБЧИСЛЮВАЛЬНОЇ МАТЕМАТИКИ}\par
			\begin{center}
	
	        \end{center}
	        \vspace{10mm}
	        \b{КУРСОВА РОБОТА}\par
	        {\small{на тему:}}\par
	        \vspace{20mm}
	        {\LARGE{\bf{\scshape{Аналіз атак на лінійні моделі машинного навчання}}}}\par
	        \vspace{5mm}
	        {}\par %subtitle
        \end{center}
	   	
	   	\vfill
	   	\hfill
		\begin{flushright}
   	   		\begin{minipage}[t]{80mm}
   	   			\flushright
	   	   		студента III курсу\\
	   	   		групи ПМп-31\\
	   	   		{Середовича Віктора}\par
	   	   		\vspace{2ex}
	   	   		Науковий керівник:\\
	   	   		{доцент Ю.А.Музичук}\\
   	   		\end{minipage}
   	   \end{flushright}
      
   	   \vspace{10mm}
   	   \begin{flushleft}
   	   \begin{minipage}[t]{80mm}
	   	   \flushleft
	   	   Завідуючий кафедри обчислювальної математики\\
	   	   проф.  
   	   \end{minipage}
   	   \end{flushleft}
   	   \vfill
   	   \vspace{10mm}
   	   
   	   \begin{center}Львів --- 2020\end{center}
   	   \stepcounter{page}
    \end{titlepage}
	% ======================================================================================== %
	
	
	% ======================================================================================== %
	\tableofcontents
	\newpage
	% ======================================================================================== %
	
	
	% ======================================================================================== %
	% ============================================ %
	\chapter{Вступ}
	\textgreater\textbf{TODO}
	Машинне начання та штучний інтелект активно використовується у різних областях нашого життя, та допомагає у вирішенні таких задач як розпізнавання дорожніх знаків, облич, визначення ризику захворювання та багато іншого.
	А з поширенням його використання, також збільшуєтья і ризик нападів зловмисників на ці алгоритми, що може привести, до трагічних наслідків. Тому варто досліджувати тему нападів на алгоритми машинного навчання, та знати як захистити свою модель. \par
	В межах теми цієї роботи будуть розглядатись різні атаки на лінійні моделі машинного начання, та методи їх захисту.
	% ============================================ %
	
	
	% ============================================ %
	\section{Постановка задачі} 
	\textit{Мета} даної роботи полягає у тому, щоб дослідити ефективність атак на лінійні моделі машинного навчання, та визначити методи захисту від них. \par
	Виходячи з мети, визначені завдання роботи:
	\begin{itemize}  
	\item Практична реалізація та дослідження методів атак
	\item Визначення методів захисту
	\end{itemize}
	% ============================================ %
	
	% ============================================ %
	\section{Класифікація атак}
	
	блаблабла \newline
	\textbf{Атаки на закриту модель (White Box attacks)} - описує такий сценарій коли в нападника  
	є повний доступ до параметрів і градієнтів моделі.  
	\newline
	\newline
	\textbf{Атаки на відкриту модель (Black Box attacks)} - це атаки при яких в нападника нема доступу до параметрів моделі. 
	\newline
	\newline
	\textbf{Цілеспрямовані атаки (Targeted Attacks)} - такі атаки, метою яких є внести у вхідний приклад такі зміни щоб модель передбачила якийсь конкретний клас.
	\newline
	\newline	
	\textbf{Нецілеспрямовані атаки (Untargeted Attacks)} - нецілеспрямованими атаками є атаки метою яких є внести в приклад такі зміни, щоб модель передбачила клас відміний від правильного, незалежно від того яким він буде.
	\newline
	\newline
	

	% ============================================ %

	% ======================================================================================== %
	
	
	% ======================================================================================== %
	% ============================================ %
	\chapter{Тренування моделі}
	В якості прикладу лінійного методу машинного навчання, на який будуть сдійснюватись атаки, буде використовуватись модифікований алгоритм логістичної регресії для мультикласової класифікації.
	
	\section{Модифікована логістична регресія}
	Задача прикладу $x \in R^{n_x}$, знайти $\hat{y}=P(y = 1 \mid x), 0 \leq \hat{y} \leq 1$
	Шукатимемо у вигляді $\hat{y} = \sigma (\omega\tran x + b)$, де
	\begin{itemize}
		\item параметри $\omega \in R^{n_x}, b \in R$ - невідомі, потрібно знайти оптимальні для для даної задачі
		\item $\sigma(z) = \frac{1}{1+ e^{-z}}$ - сигмоїд
	\end{itemize}
	Для кожного прикладу з тренувального датасету потрібно обчислити:
	\begin{itemize}
		\item $ z\ith = \omega\tran x\ith + b $
		\item $ y\ith = \sigma\ith (z\ith) $
	\end{itemize}
	де $\sigma(z\ith) = \frac{1}{1 + e^{-z\ith}}$, так щоб $\hat{y}\ith \approx y\ith $ \newline
	Для кожного прикладу визначена функція втрати:
	$$L(\hat{y}\ith, y\ith) = -y\ith \log(\hat{y}\ith) - (1 - y\ith) \log(1 - \hat{y}\ith)$$
	На всіх прикладах обчислюємо штрафну функцію як:
	$$J(w, b) = \frac{1}{m} \sum_{i=1}^{m} L(\hat{y}\ith, y\ith)$$
	
	Задача полягає в тому щоб знайти параметри $w \in R^n_x, b\in R$ що мінімізують функцію $J(\omega, b)$
	Для цього будемо використовувати градієнтний спуск 
	
	
	
	% ============================================ %
	% ======================================================================================== %


	% ======================================================================================== %
	\chapter{Методи атак} 
	% ============================================ %
	\section{Метод Швидкого Градієнту} 
	Першим методом атаки який буде розглядатись є методу швидкого градієнту (Fast Gradient Sign Method).
	
	Однокроковий метод градыэнтного стуску, FGSM, щоб знайти такий adversarial приклад $x^{*}$ який максимызую функцію втрати $J(x^{*}, y)$, де J є функцією кросс-ентропії.
	
	$ X^{*} = X + \epsilon \cdot sign(\Delta_x J(x, y))$, 
	
	де $\Delta_x J(x, y)$
	
	
	Ідея полягає в тому ..=.
	
	\begin{align*}
		z_i = \omega\tran x\ith + b \quad
		\hat{y}_i = a_i = softmax(z_i) \quad
		softmax(z_i) = \frac{e^{z_i}}{\sum_{k=1}^{c} e_k^z} \quad
	\end{align*}
	\textbf{Похідна softmax функції} \newline
	Якщо $i = j$,
	\begin{align*}
	    \pdv{\hat{y_i}}{z_j} 
	    &=
	    \pdv{\frac{e^{z_i}}{\sum_{k=1}^{c} e_k^z}}{z_j} 
	    =
	    \frac{e^{z_i} \sum_{k=1}^{c} e^{z_k} - e^{z_j} e^{z_i}}{(\sum_{k=1}^{c}  e^{z_k})^2} 
	    = \\
	    & =
	    \frac{e^{z_j}}{\sum_{k=1}^{c}  e^{z_k}} \times \frac{(\sum_{k=1}^{c} e^{z_k} - e^{z_j})}{\sum_{k=1}^{c}  e^{z_k}} 
	    = 
	    y_i(1-y_j)
	\end{align*}
	Якщо $i \neq j$,
	\begin{align*}
		\pdv{\hat{y_i}}{z_j}
		&=
		\pdv{\frac{e^{z_i}}{\sum_{k=1}^{c} e_k^z}}{z_j} 
		=
		\frac{0 - e^{z_j} e^{z_i}}{\sum_{k=1}^{c}  e^{z_k}} \times \frac{e^{z_i}}{\sum_{k=1}^{c} e^{z_k}} 
		= 
		-y_i y_j 
	\end{align*}
	
	\textbf{Функція кросс-ентропії}
	\begin{align*}
		\xi(y, x) = - \sum_{i=1}^{c} y_i  \log (\hat{y_i})
	\end{align*}
	
	\textbf{Функція кросс-ентропії}
	\begin{align*}
		\pdv{\xi}{z_i} 
		&= 
		- \sum_{j=1}^{c} \pdv{ y_j \log (\hat{y_j})}{z_i} 
		=
		- \sum_{j=1}^{c} y_j \pdv{ \log (\hat{y_j})}{z_i} 
		= \\&
		- \sum_{j=1}^{c} y_j \frac{1}{\hat{y_i}} \cdot \pdv{\hat{y_i}}{z_i} = 
		- \frac{y_i}{\hat{y_i}} \pdv{\hat{y_i}}{z_i} - \sum_{j \neq i} \frac{y_j}{\hat{y_j}} \pdv{\hat{y_j}}{z_i} 
		= \\& =
		-\frac{y_i}{\hat{y_i}} \hat{y_i} (1 - \hat{y_i}) - \sum_{j \neq i} \frac{y_j}{\hat{y_j}} (-\hat{y_i} \hat{y_j}) 
		=
		-y_i + y_i \hat{y_i} + \sum_{j \neq i} y_j \hat{y_i}
		= \\& =
		-y_i + \sum_{j=1}^{c} y_j \hat{y_i} 
		=
		\hat{y_i} - y_i
	\end{align*}
	, i = 1, ..., C
	
	\textbf{Обчислення урадієнту "має бути вище"}
	\begin{align*}
		\pdv{\xi}{x_i} 
		&=
		\pdv{\xi}{z_i} \pdv{z_i}{x_i} 
		=
		(\hat{y_i} - y_i) \pdv{(\omega\tran x_i+ b)}{x_i} 
		=
		(\hat{y_i} - y_i) x_i 
		=
		dz \cdot x
	\end{align*}
	
	\textbf{Обчислення урадієнту "має бути вище"}
	
	\begin{algorithm}[H]		
		\SetAlgoLined
		\KwIn{Приклад $x$, значення цілі y, класифікатор $f$.}
		\KwOut{ Adversarial $x^{*}$. } 
		
		Ініціалізація $x^{*} \leftarrow x. $
		
		\KwResult{Write here the result }
		initialization\;
		\While{$\hat{k}(x_i) = \hat{k}(x^{*})$}{
			$x^{*} = x^{*} - \alpha \cdot sign(\Delta_x J(x, y))$
		}
		\caption{I-FGSM атака}
	\end{algorithm}
	% ============================================ %
	
	% ============================================ %
	\section{Нецілеспрямовані атаки} 
	Основна частина даної роботи полягала у написанні програми. Нижче наводимо основний алгоритм її роботи, на мові C:
	% ============================================ %
	
	% ============================================ %
	\begin{lstlisting}[language=Python]
	% ============================================ %
	#include &lt;stdio.h&gt;
	int main() 
	{ 
	printf("Hello, world!\n"); 
	return 0; 
	} 
	\end{lstlisting}[language=Python]

	\lstset{language=Python}
	\begin{lstlisting}
	def fit(self, X, w, b, y, alpha, max_iters, predict_func):
		# Check that X and y have correct shape
		self.w = w
		self.b = b
		
		self.y_ = np.expand_dims(y.T, axis=1)
		self.X_ = X.T
		
		self.num_iters = 0
		self.X_ = self._gradient_descent(self.X_, self.y_, self.w, self.b, alpha, max_iters, predict_func)
		
		def _cost_function(self, X, Y, A):
		m = X.shape[0]
		if m == 0:
		return None
		
		J = (1 / m) * np.sum(-Y * np.log(A) - (1 - Y) * np.log(1 - A))
		return J
	\end{lstlisting}
	
	\begin{algorithm}[H]
		\SetAlgoLined
		\KwResult{Write here the result }
		initialization\;
		\While{While condition}{
			instructions\;
			\eIf{condition}{
				instructions1\;
				instructions2\;
			}{
				instructions3\;
			}
		}
		\caption{How to write algorithms}
	\end{algorithm}
	
	% ============================================ %
	
	
	% ============================================ %
	\chapter{Альтернативні рішення} 
	Деякі дослідники пишуть свої роботи в програмах типу Microsoft Word. Але то не є труйово\cite{howto}.
	% ============================================ %
	
	
	% ============================================ %	
	\chapter{Висновок} 
	Дана робота містить значний мій вклад, і перевершує попередні досягнення в багатьох напрямках. Окрім того, даний напрямок досліджень має значні перспективи
	подальшого розвитку. (Особливо добре було б, якби хтось вирішив проблему кирилиці в listings).
	% ======================================================================================== %
	
	
	% ============================================ %	
	\newpage
	\addcontentsline{toc}{chapter}{Література}
	\begin{thebibliography}{9}
		
		\bibitem{howto} Вікіпідручник \emph{Як написати курсову?}
		(\url{http://uk.wikibooks.org/wiki/%D0%AF%D0%BA_%D0%B2%D1%87%D0%B8%D1%82%D0%B8%D1%81%D1%8C_%D0%BA%D1%80%D0%B0%D1%89%D0%B5%3F/%D0%9A%D1%83%D1%80%D1%81%D0%BE%D0%B2%D1%96})
			
		\end{thebibliography}
	% ============================================ %
	
\end{document}